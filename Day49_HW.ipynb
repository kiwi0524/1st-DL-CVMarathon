{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Day49_HW.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CG77DrrB2CrU"},"source":["## 作業\n","\n","1. 如何使用已經訓練好的模型？\n","2. 依照 https://github.com/qqwweee/keras-yolo3 的程式碼，請敘述，訓練模型時，資料集的格式是什麼？具體一點的說，要提供什麼格式的文件來描述資料集的圖片以及 bboxes 的信息呢？\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NCEP-DG0VxlV","colab":{"base_uri":"https://localhost:8080/","height":118},"executionInfo":{"status":"ok","timestamp":1594556503340,"user_tz":-480,"elapsed":6468,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}},"outputId":"e5e571b4-2e60-4d60-aaa0-6be41c210938"},"source":["%tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n","1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eXT7SQe0KQxv","colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"status":"ok","timestamp":1594556508482,"user_tz":-480,"elapsed":11159,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}},"outputId":"d85a6721-8831-48c5-b841-1a60531676bd"},"source":["pip install keras==2.2.4 # 需要安裝 keras 2.2.4 的版本"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting keras==2.2.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n","\r\u001b[K     |█                               | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 112kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 133kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 163kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 184kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 225kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 245kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 256kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 266kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 276kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 296kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 3.3MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.3.1\n","    Uninstalling Keras-2.3.1:\n","      Successfully uninstalled Keras-2.3.1\n","Successfully installed keras-2.2.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vELO-PTVxAtm","colab":{"base_uri":"https://localhost:8080/","height":154},"executionInfo":{"status":"ok","timestamp":1594556568852,"user_tz":-480,"elapsed":68592,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}},"outputId":"8bdd41d7-22c0-4ada-cd62-e448519e9318"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive') # 將 google drive 掛載在 colob，\n","# 下載基於 keras 的 yolov3 程式碼\n","%cd 'gdrive/My Drive'\n","# !git clone https://github.com/qqwweee/keras-yolo3 # 如果之前已經下載過就可以註解掉\n","%cd keras-yolo3"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","/content/gdrive/My Drive\n","/content/gdrive/My Drive/keras-yolo3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T2rAjWHe-v4t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594556615316,"user_tz":-480,"elapsed":704,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}},"outputId":"b55070fd-1324-4cb1-ad15-2b9f3c1d4960"},"source":["import os\n","if not os.path.exists(\"model_data/yolo.h5\"):\n","  # 下載 yolov3 的網路權重，並且把權重轉換為 keras 能夠讀取的格式\n","    print(\"Model doesn't exist, downloading...\")\n","    #os.system(\"wget https://pjreddie.com/media/files/yolov3.weights\")\n","    print(\"Converting yolov3.weights to yolo.h5...\")\n","    os.system(\"python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5\")\n","    print(\"done\")\n","else:\n","    print(\"Model exist\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Model exist\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TeET6b1drgUK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594556569058,"user_tz":-480,"elapsed":67404,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}},"outputId":"c718200f-aaa0-4a3a-f01d-2b1ecfa1e1b8"},"source":["# 直接下載 VOC2007 的資料集作為範例\n","import os\n","if not os.path.exists(\"VOCdevkit\"):\n","    #os.system(\"wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\") # 下載 VOC 資料集\n","    os.system(\"tar xvf VOCtrainval_06-Nov-2007.tar\") # 解壓縮資料集，會花幾分鐘\n","else:\n","    print(\"data exists\")\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["data exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"suK0aCCcrnog","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594556578428,"user_tz":-480,"elapsed":74383,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}},"outputId":"db10f2ba-2739-4b37-82ca-6dae8c628d7e"},"source":["# 下載 kangaroo 資料集\n","if not os.path.exists(\"kangaroo_data\"):\n","    if not os.path.exists(\"kangaroo_data.zip\"):\n","        os.system(\"wget -O kangaroo_data.zip https://github.com/experiencor/kangaroo/archive/master.zip\")\n","    !unzip kangaroo_data.zip\n","    !mv kangaroo-master kangaroo_data\n","else:\n","    print(\"data exists\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Archive:  kangaroo_data.zip\n","882bbbd75ba49cb8cf9393e06d88ebaec293af32\n","   creating: kangaroo-master/\n","  inflating: kangaroo-master/README.md  \n","   creating: kangaroo-master/annots/\n","  inflating: kangaroo-master/annots/00001.xml  \n","  inflating: kangaroo-master/annots/00002.xml  \n","  inflating: kangaroo-master/annots/00003.xml  \n","  inflating: kangaroo-master/annots/00004.xml  \n","  inflating: kangaroo-master/annots/00005.xml  \n","  inflating: kangaroo-master/annots/00006.xml  \n","  inflating: kangaroo-master/annots/00007.xml  \n","  inflating: kangaroo-master/annots/00009.xml  \n","  inflating: kangaroo-master/annots/00010.xml  \n","  inflating: kangaroo-master/annots/00011.xml  \n","  inflating: kangaroo-master/annots/00012.xml  \n","  inflating: kangaroo-master/annots/00013.xml  \n","  inflating: kangaroo-master/annots/00014.xml  \n","  inflating: kangaroo-master/annots/00016.xml  \n","  inflating: kangaroo-master/annots/00017.xml  \n","  inflating: kangaroo-master/annots/00018.xml  \n","  inflating: kangaroo-master/annots/00019.xml  \n","  inflating: kangaroo-master/annots/00020.xml  \n","  inflating: kangaroo-master/annots/00021.xml  \n","  inflating: kangaroo-master/annots/00022.xml  \n","  inflating: kangaroo-master/annots/00023.xml  \n","  inflating: kangaroo-master/annots/00024.xml  \n","  inflating: kangaroo-master/annots/00025.xml  \n","  inflating: kangaroo-master/annots/00026.xml  \n","  inflating: kangaroo-master/annots/00027.xml  \n","  inflating: kangaroo-master/annots/00028.xml  \n","  inflating: kangaroo-master/annots/00029.xml  \n","  inflating: kangaroo-master/annots/00030.xml  \n","  inflating: kangaroo-master/annots/00031.xml  \n","  inflating: kangaroo-master/annots/00032.xml  \n","  inflating: kangaroo-master/annots/00033.xml  \n","  inflating: kangaroo-master/annots/00034.xml  \n","  inflating: kangaroo-master/annots/00036.xml  \n","  inflating: kangaroo-master/annots/00037.xml  \n","  inflating: kangaroo-master/annots/00038.xml  \n","  inflating: kangaroo-master/annots/00039.xml  \n","  inflating: kangaroo-master/annots/00040.xml  \n","  inflating: kangaroo-master/annots/00041.xml  \n","  inflating: kangaroo-master/annots/00042.xml  \n","  inflating: kangaroo-master/annots/00043.xml  \n","  inflating: kangaroo-master/annots/00044.xml  \n","  inflating: kangaroo-master/annots/00045.xml  \n","  inflating: kangaroo-master/annots/00046.xml  \n","  inflating: kangaroo-master/annots/00047.xml  \n","  inflating: kangaroo-master/annots/00048.xml  \n","  inflating: kangaroo-master/annots/00049.xml  \n","  inflating: kangaroo-master/annots/00050.xml  \n","  inflating: kangaroo-master/annots/00051.xml  \n","  inflating: kangaroo-master/annots/00052.xml  \n","  inflating: kangaroo-master/annots/00053.xml  \n","  inflating: kangaroo-master/annots/00054.xml  \n","  inflating: kangaroo-master/annots/00055.xml  \n","  inflating: kangaroo-master/annots/00056.xml  \n","  inflating: kangaroo-master/annots/00059.xml  \n","  inflating: kangaroo-master/annots/00060.xml  \n","  inflating: kangaroo-master/annots/00061.xml  \n","  inflating: kangaroo-master/annots/00062.xml  \n","  inflating: kangaroo-master/annots/00064.xml  \n","  inflating: kangaroo-master/annots/00065.xml  \n","  inflating: kangaroo-master/annots/00066.xml  \n","  inflating: kangaroo-master/annots/00069.xml  \n","  inflating: kangaroo-master/annots/00071.xml  \n","  inflating: kangaroo-master/annots/00072.xml  \n","  inflating: kangaroo-master/annots/00073.xml  \n","  inflating: kangaroo-master/annots/00074.xml  \n","  inflating: kangaroo-master/annots/00075.xml  \n","  inflating: kangaroo-master/annots/00076.xml  \n","  inflating: kangaroo-master/annots/00077.xml  \n","  inflating: kangaroo-master/annots/00078.xml  \n","  inflating: kangaroo-master/annots/00079.xml  \n","  inflating: kangaroo-master/annots/00080.xml  \n","  inflating: kangaroo-master/annots/00081.xml  \n","  inflating: kangaroo-master/annots/00083.xml  \n","  inflating: kangaroo-master/annots/00084.xml  \n","  inflating: kangaroo-master/annots/00085.xml  \n","  inflating: kangaroo-master/annots/00086.xml  \n","  inflating: kangaroo-master/annots/00087.xml  \n","  inflating: kangaroo-master/annots/00088.xml  \n","  inflating: kangaroo-master/annots/00089.xml  \n","  inflating: kangaroo-master/annots/00090.xml  \n","  inflating: kangaroo-master/annots/00091.xml  \n","  inflating: kangaroo-master/annots/00092.xml  \n","  inflating: kangaroo-master/annots/00093.xml  \n","  inflating: kangaroo-master/annots/00094.xml  \n","  inflating: kangaroo-master/annots/00095.xml  \n","  inflating: kangaroo-master/annots/00096.xml  \n","  inflating: kangaroo-master/annots/00097.xml  \n","  inflating: kangaroo-master/annots/00098.xml  \n","  inflating: kangaroo-master/annots/00099.xml  \n","  inflating: kangaroo-master/annots/00100.xml  \n","  inflating: kangaroo-master/annots/00101.xml  \n","  inflating: kangaroo-master/annots/00102.xml  \n","  inflating: kangaroo-master/annots/00103.xml  \n","  inflating: kangaroo-master/annots/00105.xml  \n","  inflating: kangaroo-master/annots/00107.xml  \n","  inflating: kangaroo-master/annots/00108.xml  \n","  inflating: kangaroo-master/annots/00109.xml  \n","  inflating: kangaroo-master/annots/00110.xml  \n","  inflating: kangaroo-master/annots/00111.xml  \n","  inflating: kangaroo-master/annots/00112.xml  \n","  inflating: kangaroo-master/annots/00113.xml  \n","  inflating: kangaroo-master/annots/00114.xml  \n","  inflating: kangaroo-master/annots/00115.xml  \n","  inflating: kangaroo-master/annots/00116.xml  \n","  inflating: kangaroo-master/annots/00117.xml  \n","  inflating: kangaroo-master/annots/00118.xml  \n","  inflating: kangaroo-master/annots/00119.xml  \n","  inflating: kangaroo-master/annots/00120.xml  \n","  inflating: kangaroo-master/annots/00121.xml  \n","  inflating: kangaroo-master/annots/00122.xml  \n","  inflating: kangaroo-master/annots/00123.xml  \n","  inflating: kangaroo-master/annots/00124.xml  \n","  inflating: kangaroo-master/annots/00125.xml  \n","  inflating: kangaroo-master/annots/00127.xml  \n","  inflating: kangaroo-master/annots/00128.xml  \n","  inflating: kangaroo-master/annots/00129.xml  \n","  inflating: kangaroo-master/annots/00130.xml  \n","  inflating: kangaroo-master/annots/00131.xml  \n","  inflating: kangaroo-master/annots/00132.xml  \n","  inflating: kangaroo-master/annots/00134.xml  \n","  inflating: kangaroo-master/annots/00136.xml  \n","  inflating: kangaroo-master/annots/00137.xml  \n","  inflating: kangaroo-master/annots/00139.xml  \n","  inflating: kangaroo-master/annots/00140.xml  \n","  inflating: kangaroo-master/annots/00141.xml  \n","  inflating: kangaroo-master/annots/00143.xml  \n","  inflating: kangaroo-master/annots/00144.xml  \n","  inflating: kangaroo-master/annots/00145.xml  \n","  inflating: kangaroo-master/annots/00146.xml  \n","  inflating: kangaroo-master/annots/00147.xml  \n","  inflating: kangaroo-master/annots/00148.xml  \n","  inflating: kangaroo-master/annots/00149.xml  \n","  inflating: kangaroo-master/annots/00150.xml  \n","  inflating: kangaroo-master/annots/00151.xml  \n","  inflating: kangaroo-master/annots/00152.xml  \n","  inflating: kangaroo-master/annots/00153.xml  \n","  inflating: kangaroo-master/annots/00154.xml  \n","  inflating: kangaroo-master/annots/00155.xml  \n","  inflating: kangaroo-master/annots/00156.xml  \n","  inflating: kangaroo-master/annots/00157.xml  \n","  inflating: kangaroo-master/annots/00158.xml  \n","  inflating: kangaroo-master/annots/00159.xml  \n","  inflating: kangaroo-master/annots/00161.xml  \n","  inflating: kangaroo-master/annots/00162.xml  \n","  inflating: kangaroo-master/annots/00163.xml  \n","  inflating: kangaroo-master/annots/00164.xml  \n","  inflating: kangaroo-master/annots/00166.xml  \n","  inflating: kangaroo-master/annots/00167.xml  \n","  inflating: kangaroo-master/annots/00168.xml  \n","  inflating: kangaroo-master/annots/00169.xml  \n","  inflating: kangaroo-master/annots/00170.xml  \n","  inflating: kangaroo-master/annots/00171.xml  \n","  inflating: kangaroo-master/annots/00172.xml  \n","  inflating: kangaroo-master/annots/00173.xml  \n","  inflating: kangaroo-master/annots/00174.xml  \n","  inflating: kangaroo-master/annots/00175.xml  \n","  inflating: kangaroo-master/annots/00176.xml  \n","  inflating: kangaroo-master/annots/00177.xml  \n","  inflating: kangaroo-master/annots/00178.xml  \n","  inflating: kangaroo-master/annots/00179.xml  \n","  inflating: kangaroo-master/annots/00180.xml  \n","  inflating: kangaroo-master/annots/00181.xml  \n","  inflating: kangaroo-master/annots/00182.xml  \n","  inflating: kangaroo-master/annots/00183.xml  \n","   creating: kangaroo-master/images/\n","  inflating: kangaroo-master/images/00001.jpg  \n","  inflating: kangaroo-master/images/00002.jpg  \n","  inflating: kangaroo-master/images/00003.jpg  \n","  inflating: kangaroo-master/images/00004.jpg  \n","  inflating: kangaroo-master/images/00005.jpg  \n","  inflating: kangaroo-master/images/00006.jpg  \n","  inflating: kangaroo-master/images/00007.jpg  \n","  inflating: kangaroo-master/images/00009.jpg  \n","  inflating: kangaroo-master/images/00010.jpg  \n","  inflating: kangaroo-master/images/00011.jpg  \n","  inflating: kangaroo-master/images/00012.jpg  \n","  inflating: kangaroo-master/images/00013.jpg  \n","  inflating: kangaroo-master/images/00014.jpg  \n","  inflating: kangaroo-master/images/00016.jpg  \n","  inflating: kangaroo-master/images/00017.jpg  \n","  inflating: kangaroo-master/images/00018.jpg  \n","  inflating: kangaroo-master/images/00019.jpg  \n","  inflating: kangaroo-master/images/00020.jpg  \n","  inflating: kangaroo-master/images/00021.jpg  \n","  inflating: kangaroo-master/images/00022.jpg  \n","  inflating: kangaroo-master/images/00023.jpg  \n","  inflating: kangaroo-master/images/00024.jpg  \n","  inflating: kangaroo-master/images/00025.jpg  \n","  inflating: kangaroo-master/images/00026.jpg  \n","  inflating: kangaroo-master/images/00027.jpg  \n","  inflating: kangaroo-master/images/00028.jpg  \n","  inflating: kangaroo-master/images/00029.jpg  \n","  inflating: kangaroo-master/images/00030.jpg  \n","  inflating: kangaroo-master/images/00031.jpg  \n","  inflating: kangaroo-master/images/00032.jpg  \n","  inflating: kangaroo-master/images/00033.jpg  \n","  inflating: kangaroo-master/images/00034.jpg  \n","  inflating: kangaroo-master/images/00036.jpg  \n","  inflating: kangaroo-master/images/00037.jpg  \n","  inflating: kangaroo-master/images/00038.jpg  \n","  inflating: kangaroo-master/images/00039.jpg  \n","  inflating: kangaroo-master/images/00040.jpg  \n","  inflating: kangaroo-master/images/00041.jpg  \n","  inflating: kangaroo-master/images/00042.jpg  \n","  inflating: kangaroo-master/images/00043.jpg  \n","  inflating: kangaroo-master/images/00044.jpg  \n","  inflating: kangaroo-master/images/00045.jpg  \n","  inflating: kangaroo-master/images/00046.jpg  \n","  inflating: kangaroo-master/images/00047.jpg  \n","  inflating: kangaroo-master/images/00048.jpg  \n","  inflating: kangaroo-master/images/00049.jpg  \n","  inflating: kangaroo-master/images/00050.jpg  \n","  inflating: kangaroo-master/images/00051.jpg  \n","  inflating: kangaroo-master/images/00052.jpg  \n","  inflating: kangaroo-master/images/00053.jpg  \n","  inflating: kangaroo-master/images/00054.jpg  \n","  inflating: kangaroo-master/images/00055.jpg  \n","  inflating: kangaroo-master/images/00056.jpg  \n","  inflating: kangaroo-master/images/00059.jpg  \n","  inflating: kangaroo-master/images/00060.jpg  \n","  inflating: kangaroo-master/images/00061.jpg  \n","  inflating: kangaroo-master/images/00062.jpg  \n","  inflating: kangaroo-master/images/00064.jpg  \n","  inflating: kangaroo-master/images/00065.jpg  \n","  inflating: kangaroo-master/images/00066.jpg  \n","  inflating: kangaroo-master/images/00069.jpg  \n","  inflating: kangaroo-master/images/00071.jpg  \n","  inflating: kangaroo-master/images/00072.jpg  \n","  inflating: kangaroo-master/images/00073.jpg  \n","  inflating: kangaroo-master/images/00074.jpg  \n","  inflating: kangaroo-master/images/00075.jpg  \n","  inflating: kangaroo-master/images/00076.jpg  \n","  inflating: kangaroo-master/images/00077.jpg  \n","  inflating: kangaroo-master/images/00078.jpg  \n","  inflating: kangaroo-master/images/00079.jpg  \n","  inflating: kangaroo-master/images/00080.jpg  \n","  inflating: kangaroo-master/images/00081.jpg  \n","  inflating: kangaroo-master/images/00083.jpg  \n","  inflating: kangaroo-master/images/00084.jpg  \n","  inflating: kangaroo-master/images/00085.jpg  \n","  inflating: kangaroo-master/images/00086.jpg  \n","  inflating: kangaroo-master/images/00087.jpg  \n","  inflating: kangaroo-master/images/00088.jpg  \n","  inflating: kangaroo-master/images/00089.jpg  \n","  inflating: kangaroo-master/images/00090.jpg  \n","  inflating: kangaroo-master/images/00091.jpg  \n","  inflating: kangaroo-master/images/00092.jpg  \n","  inflating: kangaroo-master/images/00093.jpg  \n","  inflating: kangaroo-master/images/00094.jpg  \n","  inflating: kangaroo-master/images/00095.jpg  \n","  inflating: kangaroo-master/images/00096.jpg  \n","  inflating: kangaroo-master/images/00097.jpg  \n","  inflating: kangaroo-master/images/00098.jpg  \n","  inflating: kangaroo-master/images/00099.jpg  \n","  inflating: kangaroo-master/images/00100.jpg  \n","  inflating: kangaroo-master/images/00101.jpg  \n","  inflating: kangaroo-master/images/00102.jpg  \n","  inflating: kangaroo-master/images/00103.jpg  \n"," extracting: kangaroo-master/images/00105.jpg  \n","  inflating: kangaroo-master/images/00107.jpg  \n","  inflating: kangaroo-master/images/00108.jpg  \n","  inflating: kangaroo-master/images/00109.jpg  \n","  inflating: kangaroo-master/images/00110.jpg  \n","  inflating: kangaroo-master/images/00111.jpg  \n","  inflating: kangaroo-master/images/00112.jpg  \n","  inflating: kangaroo-master/images/00113.jpg  \n","  inflating: kangaroo-master/images/00114.jpg  \n","  inflating: kangaroo-master/images/00115.jpg  \n","  inflating: kangaroo-master/images/00116.jpg  \n","  inflating: kangaroo-master/images/00117.jpg  \n","  inflating: kangaroo-master/images/00118.jpg  \n","  inflating: kangaroo-master/images/00119.jpg  \n","  inflating: kangaroo-master/images/00120.jpg  \n","  inflating: kangaroo-master/images/00121.jpg  \n","  inflating: kangaroo-master/images/00122.jpg  \n","  inflating: kangaroo-master/images/00123.jpg  \n","  inflating: kangaroo-master/images/00124.jpg  \n","  inflating: kangaroo-master/images/00125.jpg  \n","  inflating: kangaroo-master/images/00127.jpg  \n","  inflating: kangaroo-master/images/00128.jpg  \n","  inflating: kangaroo-master/images/00129.jpg  \n","  inflating: kangaroo-master/images/00130.jpg  \n","  inflating: kangaroo-master/images/00131.jpg  \n"," extracting: kangaroo-master/images/00132.jpg  \n","  inflating: kangaroo-master/images/00134.jpg  \n","  inflating: kangaroo-master/images/00136.jpg  \n","  inflating: kangaroo-master/images/00137.jpg  \n","  inflating: kangaroo-master/images/00139.jpg  \n","  inflating: kangaroo-master/images/00140.jpg  \n","  inflating: kangaroo-master/images/00141.jpg  \n","  inflating: kangaroo-master/images/00143.jpg  \n"," extracting: kangaroo-master/images/00144.jpg  \n","  inflating: kangaroo-master/images/00145.jpg  \n","  inflating: kangaroo-master/images/00146.jpg  \n","  inflating: kangaroo-master/images/00147.jpg  \n","  inflating: kangaroo-master/images/00148.jpg  \n","  inflating: kangaroo-master/images/00149.jpg  \n","  inflating: kangaroo-master/images/00150.jpg  \n","  inflating: kangaroo-master/images/00151.jpg  \n","  inflating: kangaroo-master/images/00152.jpg  \n","  inflating: kangaroo-master/images/00153.jpg  \n","  inflating: kangaroo-master/images/00154.jpg  \n"," extracting: kangaroo-master/images/00155.jpg  \n","  inflating: kangaroo-master/images/00156.jpg  \n","  inflating: kangaroo-master/images/00157.jpg  \n","  inflating: kangaroo-master/images/00158.jpg  \n","  inflating: kangaroo-master/images/00159.jpg  \n","  inflating: kangaroo-master/images/00161.jpg  \n","  inflating: kangaroo-master/images/00162.jpg  \n","  inflating: kangaroo-master/images/00163.jpg  \n","  inflating: kangaroo-master/images/00164.jpg  \n","  inflating: kangaroo-master/images/00166.jpg  \n"," extracting: kangaroo-master/images/00167.jpg  \n","  inflating: kangaroo-master/images/00168.jpg  \n","  inflating: kangaroo-master/images/00169.jpg  \n","  inflating: kangaroo-master/images/00170.jpg  \n","  inflating: kangaroo-master/images/00171.jpg  \n","  inflating: kangaroo-master/images/00172.jpg  \n","  inflating: kangaroo-master/images/00173.jpg  \n","  inflating: kangaroo-master/images/00174.jpg  \n","  inflating: kangaroo-master/images/00175.jpg  \n","  inflating: kangaroo-master/images/00176.jpg  \n","  inflating: kangaroo-master/images/00177.jpg  \n","  inflating: kangaroo-master/images/00178.jpg  \n","  inflating: kangaroo-master/images/00179.jpg  \n","  inflating: kangaroo-master/images/00180.jpg  \n","  inflating: kangaroo-master/images/00181.jpg  \n","  inflating: kangaroo-master/images/00182.jpg  \n","  inflating: kangaroo-master/images/00183.jpg  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nPB1nMRM-2Zb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594556642916,"user_tz":-480,"elapsed":659,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}}},"source":["import os\n","if not os.path.exists(\"2007_train.txt\"): # 範例中訓練模型時所使用的，已經做好轉換的 annotation 檔名，增加這個檢查避免每次重新跑這段轉換的程式碼\n","    import xml.etree.ElementTree as ET # 載入能夠 Parser xml 文件的 library\n","    from os import getcwd\n","\n","    sets=[('2007', 'train'), ('2007', 'val')]\n","\n","  # Pascal VOC 的資料類別\n","    classes = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n","\n","  # 把 annotation 轉換訓練時需要的資料形態\n","def convert_annotation(year, image_id, list_file):\n","    in_file = open('VOCdevkit/VOC%s/Annotations/%s.xml'%(year, image_id))\n","    tree=ET.parse(in_file)\n","    root = tree.getroot()\n","\n","    for obj in root.iter('object'):\n","        difficult = obj.find('difficult').text\n","        cls = obj.find('name').text\n","        if cls not in classes or int(difficult)==1:\n","            continue\n","        cls_id = classes.index(cls)\n","        xmlbox = obj.find('bndbox')\n","        b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))\n","        list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n","\n","    wd = \".\"\n","\n","    for year, image_set in sets:\n","        image_ids = open('VOCdevkit/VOC%s/ImageSets/Main/%s.txt'%(year, image_set)).read().strip().split()\n","        annotation_path = '%s_%s.txt'%(year, image_set)\n","        list_file = open(annotation_path, 'w')\n","        print(\"save annotation at %s\" % annotation_path)\n","        for image_id in image_ids[:100]: # 只處理 100 張圖片來做範例\n","            list_file.write('%s/VOCdevkit/VOC%s/JPEGImages/%s.jpg'%(wd, year, image_id))\n","            convert_annotation(year, image_id, list_file)\n","            list_file.write('\\n')\n","        list_file.close()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"8c_7Jvfj-8DL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594556665022,"user_tz":-480,"elapsed":1348,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}},"outputId":"2047e554-283c-4537-f9bb-244339b53e7a"},"source":["# 將 train.py 所需要的套件載入\n","import numpy as np\n","import keras.backend as K\n","from keras.layers import Input, Lambda\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","\n","from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n","from yolo3.utils import get_random_data"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"7cSVm4Gq_BY7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594556686302,"user_tz":-480,"elapsed":797,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}}},"source":["from train import get_classes, get_anchors, create_model, create_tiny_model, data_generator, data_generator_wrapper"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Zmu85Jl_FRT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594556701806,"user_tz":-480,"elapsed":562,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}},"outputId":"7eed9626-cd64-4c4e-90fe-f8e5e0256f38"},"source":["if not os.path.exists(\"model_data/yolo_weights.h5\"):\n","    print(\"Converting pretrained YOLOv3 weights for training\")\n","    os.system(\"python convert.py -w yolov3.cfg yolov3.weights model_data/yolo_weights.h5\") \n","else:\n","    print(\"Pretrained weights exists\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Pretrained weights exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XPIq3-J2_Jy7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1594557285666,"user_tz":-480,"elapsed":565642,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}},"outputId":"e6d5fa81-a3a4-420d-99d4-c6596d1f9886"},"source":["from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","\n","annotation_path = '2007_train.txt' # 轉換好格式的標註檔案\n","log_dir = 'logs/000/' # 訓練好的模型儲存的路徑\n","classes_path = 'model_data/voc_classes.txt'\n","anchors_path = 'model_data/yolo_anchors.txt'\n","class_names = get_classes(classes_path)\n","num_classes = len(class_names)\n","anchors = get_anchors(anchors_path)\n","\n","input_shape = (416,416) # multiple of 32, hw\n","\n","is_tiny_version = len(anchors)==6 # default setting\n","if is_tiny_version:\n","    model = create_tiny_model(input_shape, anchors, num_classes,\n","        freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n","else:\n","    model = create_model(input_shape, anchors, num_classes,\n","        freeze_body=2, weights_path='model_data/yolo_weights.h5') # make sure you know what you freeze\n","\n","logging = TensorBoard(log_dir=log_dir)\n","checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n","    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n","\n","# 分為 training 以及 validation\n","val_split = 0.1\n","with open(annotation_path) as f:\n","    lines = f.readlines()\n","np.random.seed(10101)\n","np.random.shuffle(lines)\n","np.random.seed(None)\n","num_val = int(len(lines)*val_split)\n","num_train = len(lines) - num_val\n","\n","# Train with frozen layers first, to get a stable loss.\n","# Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n","# 一開始先 freeze YOLO 除了 output layer 以外的 darknet53 backbone 來 train\n","if True:\n","    model.compile(optimizer=Adam(lr=1e-3), loss={\n","        # use custom yolo_loss Lambda layer.\n","        'yolo_loss': lambda y_true, y_pred: y_pred})\n","\n","    batch_size = 16\n","    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n","    # 模型利用 generator 產生的資料做訓練，強烈建議大家去閱讀及理解 data_generator_wrapper 在 train.py 中的實現\n","    model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n","            steps_per_epoch=max(1, num_train//batch_size),\n","            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n","            validation_steps=max(1, num_val//batch_size),\n","            epochs=50,\n","            initial_epoch=0,\n","            callbacks=[logging, checkpoint])\n","    \n","    model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n","\n","# Unfreeze and continue training, to fine-tune.\n","# Train longer if the result is not good.\n","if True:\n","    # 把所有 layer 都改為 trainable\n","    for i in range(len(model.layers)):\n","        model.layers[i].trainable = True\n","    model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n","    print('Unfreeze all of the layers.')\n","\n","    batch_size = 16 # note that more GPU memory is required after unfreezing the body\n","    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n","    model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n","        steps_per_epoch=max(1, num_train//batch_size),\n","        validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n","        validation_steps=max(1, num_val//batch_size),\n","        epochs=100,\n","        initial_epoch=50,\n","        callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n","    model.save_weights(log_dir + 'trained_weights_final.h5')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","Create YOLOv3 model with 9 anchors and 20 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 75) vs (255, 1024, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((75,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 75) vs (255, 512, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((75,) vs (255,)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 75) vs (255, 256, 1, 1)).\n","  weight_values[i].shape))\n","/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1140: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((75,) vs (255,)).\n","  weight_values[i].shape))\n"],"name":"stderr"},{"output_type":"stream","text":["Load weights model_data/yolo_weights.h5.\n","Freeze the first 249 layers of total 252 layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3080: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","Train on 90 samples, val on 10 samples, with batch size 16.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","Epoch 1/50\n","5/5 [==============================] - 59s 12s/step - loss: 9879.0026 - val_loss: 7599.0024\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n","Epoch 2/50\n","5/5 [==============================] - 7s 1s/step - loss: 5836.1160 - val_loss: 4537.2466\n","Epoch 3/50\n","5/5 [==============================] - 8s 2s/step - loss: 3464.7898 - val_loss: 2677.3411\n","Epoch 4/50\n","5/5 [==============================] - 4s 884ms/step - loss: 2112.0095 - val_loss: 1674.6416\n","Epoch 5/50\n","5/5 [==============================] - 4s 875ms/step - loss: 1321.5502 - val_loss: 1081.7760\n","Epoch 6/50\n","5/5 [==============================] - 4s 874ms/step - loss: 898.5560 - val_loss: 744.5599\n","Epoch 7/50\n","5/5 [==============================] - 5s 1s/step - loss: 654.1676 - val_loss: 581.6666\n","Epoch 8/50\n","5/5 [==============================] - 8s 2s/step - loss: 502.2827 - val_loss: 468.3609\n","Epoch 9/50\n","5/5 [==============================] - 8s 2s/step - loss: 408.5242 - val_loss: 421.3745\n","Epoch 10/50\n","5/5 [==============================] - 7s 1s/step - loss: 349.2257 - val_loss: 347.2690\n","Epoch 11/50\n","5/5 [==============================] - 8s 2s/step - loss: 310.7572 - val_loss: 292.8524\n","Epoch 12/50\n","5/5 [==============================] - 8s 2s/step - loss: 272.5151 - val_loss: 282.0283\n","Epoch 13/50\n","5/5 [==============================] - 7s 1s/step - loss: 251.2444 - val_loss: 238.1867\n","Epoch 14/50\n","5/5 [==============================] - 8s 2s/step - loss: 235.2851 - val_loss: 222.5981\n","Epoch 15/50\n","5/5 [==============================] - 8s 2s/step - loss: 215.7009 - val_loss: 224.2970\n","Epoch 16/50\n","5/5 [==============================] - 7s 1s/step - loss: 201.9276 - val_loss: 192.6657\n","Epoch 17/50\n","5/5 [==============================] - 8s 2s/step - loss: 188.1378 - val_loss: 203.8494\n","Epoch 18/50\n","5/5 [==============================] - 8s 2s/step - loss: 179.8430 - val_loss: 175.3519\n","Epoch 19/50\n","5/5 [==============================] - 8s 2s/step - loss: 169.4757 - val_loss: 173.1460\n","Epoch 20/50\n","5/5 [==============================] - 8s 2s/step - loss: 162.1841 - val_loss: 168.0041\n","Epoch 21/50\n","5/5 [==============================] - 8s 2s/step - loss: 154.1956 - val_loss: 161.3964\n","Epoch 22/50\n","5/5 [==============================] - 7s 1s/step - loss: 148.6138 - val_loss: 152.8852\n","Epoch 23/50\n","5/5 [==============================] - 8s 2s/step - loss: 140.3712 - val_loss: 152.7260\n","Epoch 24/50\n","5/5 [==============================] - 8s 2s/step - loss: 134.8010 - val_loss: 138.3306\n","Epoch 25/50\n","5/5 [==============================] - 7s 1s/step - loss: 127.8462 - val_loss: 126.9900\n","Epoch 26/50\n","5/5 [==============================] - 8s 2s/step - loss: 127.3816 - val_loss: 130.8096\n","Epoch 27/50\n","5/5 [==============================] - 8s 2s/step - loss: 121.1063 - val_loss: 122.0440\n","Epoch 28/50\n","5/5 [==============================] - 7s 1s/step - loss: 116.3982 - val_loss: 126.2756\n","Epoch 29/50\n","5/5 [==============================] - 8s 2s/step - loss: 114.5353 - val_loss: 118.5539\n","Epoch 30/50\n","5/5 [==============================] - 8s 2s/step - loss: 107.4878 - val_loss: 124.0293\n","Epoch 31/50\n","5/5 [==============================] - 8s 2s/step - loss: 105.9991 - val_loss: 112.8509\n","Epoch 32/50\n","5/5 [==============================] - 8s 2s/step - loss: 107.7365 - val_loss: 122.8484\n","Epoch 33/50\n","5/5 [==============================] - 8s 2s/step - loss: 99.0311 - val_loss: 92.2027\n","Epoch 34/50\n","5/5 [==============================] - 8s 2s/step - loss: 99.6038 - val_loss: 117.6009\n","Epoch 35/50\n","5/5 [==============================] - 8s 2s/step - loss: 96.4523 - val_loss: 95.8182\n","Epoch 36/50\n","5/5 [==============================] - 8s 2s/step - loss: 93.1456 - val_loss: 106.9277\n","Epoch 37/50\n","5/5 [==============================] - 8s 2s/step - loss: 87.9234 - val_loss: 110.2910\n","Epoch 38/50\n","5/5 [==============================] - 8s 2s/step - loss: 89.4603 - val_loss: 90.8360\n","Epoch 39/50\n","5/5 [==============================] - 8s 2s/step - loss: 89.5939 - val_loss: 91.6586\n","Epoch 40/50\n","5/5 [==============================] - 8s 2s/step - loss: 83.1212 - val_loss: 86.3332\n","Epoch 41/50\n","5/5 [==============================] - 8s 2s/step - loss: 83.2786 - val_loss: 100.9788\n","Epoch 42/50\n","5/5 [==============================] - 8s 2s/step - loss: 81.3668 - val_loss: 85.8117\n","Epoch 43/50\n","5/5 [==============================] - 7s 1s/step - loss: 76.2050 - val_loss: 91.2553\n","Epoch 44/50\n","5/5 [==============================] - 8s 2s/step - loss: 75.9118 - val_loss: 84.9853\n","Epoch 45/50\n","5/5 [==============================] - 8s 2s/step - loss: 76.4568 - val_loss: 75.1644\n","Epoch 46/50\n","5/5 [==============================] - 7s 1s/step - loss: 74.6310 - val_loss: 73.5723\n","Epoch 47/50\n","5/5 [==============================] - 8s 2s/step - loss: 75.3356 - val_loss: 82.2834\n","Epoch 48/50\n","5/5 [==============================] - 8s 2s/step - loss: 72.4197 - val_loss: 78.6225\n","Epoch 49/50\n","5/5 [==============================] - 8s 2s/step - loss: 72.1357 - val_loss: 86.3725\n","Epoch 50/50\n","5/5 [==============================] - 8s 2s/step - loss: 68.0754 - val_loss: 75.3247\n","Unfreeze all of the layers.\n","Train on 90 samples, val on 10 samples, with batch size 16.\n","Epoch 51/100\n"],"name":"stdout"},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-fc6edb5bb52e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'trained_weights_final.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[16,128,52,52] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node batch_normalization_67/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss_1/add_74/_5299]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[16,128,52,52] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node batch_normalization_67/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."]}]},{"cell_type":"code","metadata":{"id":"e8zH12Ys_OOz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":554},"executionInfo":{"status":"ok","timestamp":1594559828477,"user_tz":-480,"elapsed":22454,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}},"outputId":"e6e17808-1953-4df6-9b84-58c616677a21"},"source":["%tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\n","import tensorflow as tf\n","print(tf.__version__)\n","%pip install keras==2.2.4 # 需要安裝 keras 2.2.4 的版本\n","from google.colab import drive \n","drive.mount('/content/gdrive') # 將 google drive 掛載在 colob，\n","# 下載基於 keras 的 yolov3 程式碼\n","%cd 'gdrive/My Drive'\n","# !git clone https://github.com/qqwweee/keras-yolo3 # 如果之前已經下載過就可以註解掉\n","%cd keras-yolo3\n","import os\n","if not os.path.exists(\"model_data/yolo.h5\"):\n","  # 下載 yolov3 的網路權重，並且把權重轉換為 keras 能夠讀取的格式\n","  print(\"Model doesn't exist, downloading...\")\n","  os.system(\"wget https://pjreddie.com/media/files/yolov3.weights\")\n","  print(\"Converting yolov3.weights to yolo.h5...\")\n","  os.system(\"python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5\")\n","else:\n","  print(\"Model exist\")\n","# 下載 raccoon 與 kangaroo 的資料集\n","if not os.path.exists(\"raccoon_dataset\"):\n","  !git clone https://github.com/experiencor/raccoon_dataset.git  # 下載 raccoon_dataset 資料集\n","else:\n","  print(\"raccoon_dataset exists\")\n","\n","if not os.path.exists(\"kangaroo\"):\n","  !git clone https://github.com/experiencor/kangaroo.git  # 下載 kangaroo 資料集\n","else:\n","  print(\"kangaroo exists\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow is already loaded. Please restart the runtime to change versions.\n","1.15.2\n","Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","[Errno 2] No such file or directory: 'gdrive/My Drive'\n","/content/gdrive/My Drive/keras-yolo3\n","[Errno 2] No such file or directory: 'keras-yolo3'\n","/content/gdrive/My Drive/keras-yolo3\n","Model exist\n","Cloning into 'raccoon_dataset'...\n","remote: Enumerating objects: 646, done.\u001b[K\n","remote: Total 646 (delta 0), reused 0 (delta 0), pack-reused 646\u001b[K\n","Receiving objects: 100% (646/646), 48.00 MiB | 15.29 MiB/s, done.\n","Resolving deltas: 100% (412/412), done.\n","Checking out files: 100% (419/419), done.\n","Cloning into 'kangaroo'...\n","remote: Enumerating objects: 334, done.\u001b[K\n","remote: Total 334 (delta 0), reused 0 (delta 0), pack-reused 334\u001b[K\n","Receiving objects: 100% (334/334), 18.39 MiB | 15.40 MiB/s, done.\n","Resolving deltas: 100% (158/158), done.\n","Checking out files: 100% (329/329), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bdNyAJoPLCds","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":185},"executionInfo":{"status":"ok","timestamp":1594559851567,"user_tz":-480,"elapsed":9934,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}},"outputId":"2cbeabb0-0bca-4453-f6b3-04eac152bfa2"},"source":["import numpy as np\n","# 訓練模型時需使用的 annotation 檔名, 若已經做好轉換, 則不會每次再重新跑這段轉換的程式碼\n","if not os.path.exists(\"train_labels.txt\"):\n","  import xml.etree.ElementTree as ET # 載入能夠 Parser xml 文件的 library\n","  \n","  sets=['train', 'val', 'test']\n","\n","  # \"raccoon\", \"kangaroo\" 的資料類別\n","  classes = [\"raccoon\", \"kangaroo\"]\n","\n","  # 把 annotation(.xml) 轉換到訓練時需要的資料形態\n","  def convert_annotation(image_id, list_file):\n","      in_file = open('annotation_xml/%s.xml'%(image_id))\n","      tree=ET.parse(in_file)\n","      root = tree.getroot()\n","\n","      for obj in root.iter('object'):\n","          difficult = obj.find('difficult').text\n","          cls = obj.find('name').text\n","          if cls not in classes or int(difficult)==1: \n","              continue\n","          cls_id = classes.index(cls)  # class index\n","          xmlbox = obj.find('bndbox')\n","          b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text), \n","                int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))\n","          list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n","\n","  # 把 raccoon_dataset/images 與 kangaroo/images 檔案合併後, 當成訓練集 & 驗證集 & 測試集資料\n","  for root,dirs,files in os.walk('raccoon_dataset/images') :\n","    print('raccoon jpg 檔數量:', len(files))\n","  for root_2,dirs_2,files_2 in os.walk('kangaroo/images') :\n","    print('kangaroo jpg 檔數量:', len(files_2))\n","  # 把 files_2 合併在 files list 內\n","  files.extend(files_2)\n","  print('所有 jpg 檔數量:', len(files))\n","    \n","  jpg_ids = ''.join(files).strip().split('.jpg')[:-1]\n","  # 70% 檔案資料當成訓練集資料\n","  train_index = np.random.choice(jpg_ids, size=int(len(jpg_ids)*0.7), replace=False)\n","  # 30%中的66%檔案資料當成驗證集資料\n","  val_test_index = np.setdiff1d(jpg_ids, train_index)\n","  val_index = np.random.choice(val_test_index, size=int(len(val_test_index)*0.66), replace=False)\n","  test_index = np.setdiff1d(val_test_index, val_index)\n","\n","  !mkdir train val test\n","  # 把訓練集資料檔索引, 放入 train 資料夾\n","  train_txt = open('train/train.txt', 'w')\n","  print(\"save train index at train/train.txt\")       \n","  for train_id in train_index : \n","      train_txt.write('%s' %(train_id))\n","      train_txt.write('\\n')\n","  train_txt.close()\n","\n","  # 把驗證集資料檔索引, 放入 val 資料夾\n","  val_txt = open('val/val.txt', 'w')\n","  print(\"save val index at val/val.txt\")       \n","  for val_id in val_index : \n","      val_txt.write('%s' %(val_id))\n","      val_txt.write('\\n')\n","  val_txt.close()\n","\n","  # 把測試集資料檔索引, 放入 test 資料夾\n","  test_txt = open('test/test.txt', 'w')\n","  print(\"save test index at test/test.txt\")       \n","  for test_id in test_index : \n","      test_txt.write('%s' %(test_id))\n","      test_txt.write('\\n')\n","  test_txt.close()\n","\n","  # 把annotation(.xml), 放入 annotation_xml 資料夾\n","  !mkdir annotation_xml\n","  !cp raccoon_dataset/annotations/*.xml ./annotation_xml\n","  !cp kangaroo/annots/*.xml ./annotation_xml\n","\n","  # 把類別資料放入 class.txt\n","  class_txt = open('class.txt', 'w')\n","  print(\"save class at class.txt\")       \n","  for class_id in classes : \n","      class_txt.write('%s' %(class_id))\n","      class_txt.write('\\n')\n","  class_txt.close()\n","\n","  for image_set in sets:\n","      image_ids = open('%s/%s.txt'%(image_set, image_set)).read().strip().split()\n","      \n","      annotation_path = '%s_labels.txt'%(image_set)\n","      list_file = open(annotation_path, 'w')\n","      print(\"save annotation at %s\" % annotation_path)\n","      # 處理訓練集 & 驗證集 & 測試集資料檔\n","      for image_id in image_ids:\n","        if 'raccoon' in image_id :\n","          list_file.write('./raccoon_dataset/images/%s.jpg' %(image_id))\n","        else :\n","          list_file.write('./kangaroo/images/%s.jpg' %(image_id))  \n","        convert_annotation(image_id, list_file)\n","        list_file.write('\\n')\n","      list_file.close()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["raccoon jpg 檔數量: 200\n","kangaroo jpg 檔數量: 164\n","所有 jpg 檔數量: 364\n","save train index at train/train.txt\n","save val index at val/val.txt\n","save test index at test/test.txt\n","save class at class.txt\n","save annotation at train_labels.txt\n","save annotation at val_labels.txt\n","save annotation at test_labels.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hNGms-apLIZk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594559861409,"user_tz":-480,"elapsed":544,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}},"outputId":"715c8d53-da48-475f-f8a0-813fd69ae0d6"},"source":["\n","# convert.py '-w' : 代表只轉換權重 weights 到 model_data/yolo_weights.h5\n","if not os.path.exists(\"model_data/yolo_weights.h5\"):\n","  print(\"Converting pretrained YOLOv3 weights for training\")\n","  os.system(\"python convert.py -w yolov3.cfg yolov3.weights model_data/yolo_weights.h5\") \n","else:\n","  print(\"Pretrained weights exists\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Pretrained weights exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NWupcJtXLMnN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594559878209,"user_tz":-480,"elapsed":550,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}}},"source":["# 將 train.py 所需要的套件載入\n","import numpy as np\n","import keras.backend as K\n","from keras.layers import Input, Lambda\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","\n","from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n","from yolo3.utils import get_random_data"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pjqpa3yCLQIt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594559894090,"user_tz":-480,"elapsed":823,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}}},"source":["from train import get_classes, get_anchors, create_model, create_tiny_model, data_generator, data_generator_wrapper\n","from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"k0MyCUeRuARA","colab":{"base_uri":"https://localhost:8080/","height":212},"executionInfo":{"status":"error","timestamp":1594559068951,"user_tz":-480,"elapsed":20375,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}},"outputId":"a0c27782-ac42-4731-9658-ac667328df8c"},"source":["\n","from yolo import YOLO\n","yolo_model = YOLO(model_path='logs/000/'+ 'trained_weights_final.h5', classes_path='model_data/voc_classes.txt')\n","r_image = yolo_model.detect_image(image)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["logs/000/trained_weights_final.h5 model, anchors, and classes loaded.\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-96b3c51f9975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myolo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0myolo_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logs/000/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'trained_weights_final.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_data/voc_classes.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mr_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolo_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"]}]},{"cell_type":"code","metadata":{"id":"vbWuY0GfLPZc","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2sj8cBafLAwu","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ooyy53TW5c0L","colab":{},"executionInfo":{"status":"aborted","timestamp":1594559068947,"user_tz":-480,"elapsed":19101,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}}},"source":["from yolo import YOLO\n","yolo_model = YOLO(model_path='logs/000/trained_weights_final.h5', classes_path=\"model_data/voc_classes.txt\")\n","r_image = yolo_model.detect_image(image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IhNNSOEU_Xlz","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594559068948,"user_tz":-480,"elapsed":17544,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}}},"source":["r_image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmJ6tc579Olj","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594559068950,"user_tz":-480,"elapsed":16372,"user":{"displayName":"陳品羚","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjx3HJQEdBYkwpvszdIV2KuuQFjSITUwSFqGu7e6g=s64","userId":"06407603029429159711"}}},"source":["with open(\"2007_train.txt\", \"r\") as f:\n","    d = f.readlines()\n","d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k84e-tn6_feK","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}